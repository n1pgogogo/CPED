{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6035231493</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>🔝置顶这条用于存放个人分享资源和工具理想是传递开源、分享、互助的互联网精神</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Speaker Neuroticism Extraversion Openness Agreeableness  \\\n",
       "0  6035231493        high          low      low           low   \n",
       "\n",
       "  Conscientiousness                               Utterance  \n",
       "0               low  🔝置顶这条用于存放个人分享资源和工具理想是传递开源、分享、互助的互联网精神   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json\n",
    "from core import start_calc, start\n",
    "\n",
    "df = pd.read_csv(\"../data/weibo/test.csv\", usecols=[\"Speaker\", \"Utterance\",\n",
    "                                                          \"Neuroticism\", \"Extraversion\", \"Openness\",\n",
    "                                                          \"Agreeableness\", \"Conscientiousness\"])\n",
    "df = df[df[\"Agreeableness\"] != \"unknown\"] # 剔除没有人格的人物\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>5345320676</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8857</th>\n",
       "      <td>5682320016</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9198</th>\n",
       "      <td>5854265900</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Speaker Neuroticism Extraversion Openness Agreeableness  \\\n",
       "6288  5345320676         low          low     high          high   \n",
       "8857  5682320016        high          low     high          high   \n",
       "9198  5854265900        high          low     high          high   \n",
       "\n",
       "     Conscientiousness  \n",
       "6288              high  \n",
       "8857              high  \n",
       "9198               low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 真实值\n",
    "r_real = pd.DataFrame([], columns=[\"Speaker\",\n",
    "                                   \"Neuroticism\", \"Extraversion\", \"Openness\",\n",
    "                                   \"Agreeableness\", \"Conscientiousness\"])\n",
    "for v, row in pd.DataFrame(df.groupby([\"Speaker\"])[\"Utterance\"].count()).sort_values(by=[\"Utterance\"], ascending=True).iloc[:, :].iterrows():\n",
    "    if not np.any(r_real[\"Speaker\"] == v):\n",
    "        # 保存真实值\n",
    "        tmpB = df[df[\"Speaker\"] == v].iloc[1, :]\n",
    "        r_real = pd.concat([r_real, pd.DataFrame(\n",
    "            [df[df[\"Speaker\"] == v].iloc[1, :-1]]\n",
    "        )])\n",
    "r_real.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gpt_res(path, v, send, content):\n",
    "    pd.concat([\n",
    "        pd.read_csv(path), pd.DataFrame(\n",
    "            [[v, send, content]],\n",
    "            columns = [\"Speaker\", \"Utter\", \"Res_Utter\"])]).to_csv(path, index=False)\n",
    "\n",
    "filename = \"weibo_form_gpt4_3\"\n",
    "# filename = \"w_gpt3.5_4.csv\"\n",
    "path = \"../data/self/{}.csv\".format(filename)\n",
    "pd.DataFrame([], columns=[\"Speaker\", \"Utter\", \"Res_Utter\"]).to_csv(\n",
    "    path, index=False)\n",
    "for v, row in pd.DataFrame(\n",
    "    df.groupby([\"Speaker\"])[\"Utterance\"].count()\n",
    ").sort_values(by=[\"Utterance\"], ascending=True).iloc[0:10, :].iterrows():\n",
    "    use_sentence = \"\"\n",
    "    use_token = 0\n",
    "    for i, row_j in df[df[\"Speaker\"] == v].iterrows():\n",
    "        use_token_sub = start_calc(use_sentence + row_j[\"Utterance\"])\n",
    "        if use_token_sub > 4000:  # 如果新增的超出token了，清空一下\n",
    "            save_gpt_res(path, v, use_sentence, start(use_sentence))\n",
    "            use_sentence = \"{}: {}\".format(v, row_j[\"Utterance\"])  # 重置句子\n",
    "        else:\n",
    "            use_sentence += \"\\n{}: {}\".format(v, row_j[\"Utterance\"])\n",
    "    save_gpt_res(path, v, use_sentence, start(use_sentence))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面获取了gpt的结果，并进行了保存，下面就开始解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"w_gpt3.5_4.csv\"\n",
    "filename = \"weibo_form_gpt4_2\"\n",
    "path = \"../data/self/{}.csv\".format(filename)\n",
    "import re\n",
    "# 预测值\n",
    "r_pre = pd.DataFrame([], columns=[\"Speaker\",\n",
    "                                  \"Neuroticism\", \"Extraversion\", \"Openness\",\n",
    "                                  \"Agreeableness\", \"Conscientiousness\"])\n",
    "gpt_res = pd.read_csv(path)\n",
    "for v, row in gpt_res.iterrows():\n",
    "    res_arr = re.findall(r\"\\{.*?\\}\", row[\"Res_Utter\"], re.S)\n",
    "    try:\n",
    "        arr = json.loads(res_arr[len(res_arr) - 1])\n",
    "        r_pre = pd.concat([r_pre, pd.DataFrame([\n",
    "            [row[\"Speaker\"], arr[\"神经质\"], arr[\"外向性\"],\n",
    "                arr[\"开放性\"], arr[\"宜人性\"], arr[\"尽责性\"]]],\n",
    "            columns=[\"Speaker\",\n",
    "                     \"Neuroticism\", \"Extraversion\", \"Openness\",\n",
    "                     \"Agreeableness\", \"Conscientiousness\"])])\n",
    "    except Exception as e:\n",
    "        print(e, len(res_arr), row[\"Speaker\"], row[\"Res_Utter\"])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuroticism          0.739130\n",
       "Extraversion         0.586957\n",
       "Openness             0.891304\n",
       "Agreeableness        0.586957\n",
       "Conscientiousness    0.434783\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新的计算准确率的方式\n",
    "y_real = r_real\n",
    "y_pre = r_pre\n",
    "for v in [\"Neuroticism\", \"Extraversion\", \"Openness\",\"Agreeableness\", \"Conscientiousness\"]:\n",
    "    y_pre[v] = y_pre[v].replace({\"低\": \"low\", \"高\": \"high\", \"中等\": \"medium\", \"不知道\": \"unknow\"})\n",
    "\n",
    "# 让真实值和预测值之间的长度统一\n",
    "y_real = y_real.loc[[np.any(y_pre[\"Speaker\"] == i) for i in y_real[\"Speaker\"]],:]\n",
    "y_pre.index = pd.Index([i for i in range(0, y_pre.shape[0])])\n",
    "y_real.index = pd.Index([i for i in range(0, y_real.shape[0])])\n",
    "\n",
    "# 开始计算准确率\n",
    "r = []\n",
    "for i, row in y_pre.iterrows():\n",
    "    for v in [\"Neuroticism\", \"Extraversion\", \"Openness\",\"Agreeableness\", \"Conscientiousness\"]:\n",
    "        r.append(1 if y_real[y_real[\"Speaker\"] == row[\"Speaker\"]][v].to_list()[0] == row[v] else 0)\n",
    "\n",
    "pd.DataFrame(np.array(r).reshape(int(len(r) / 5), 5), columns=[\"Neuroticism\", \"Extraversion\", \"Openness\",\"Agreeableness\", \"Conscientiousness\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuroticism\t0.6\n",
      "Extraversion\t0.5\n",
      "Openness\t1.0\n",
      "Agreeableness\t0.8\n",
      "Conscientiousness\t0.6\n"
     ]
    }
   ],
   "source": [
    "# 去除无效的值\n",
    "judge1 = lambda x: x if x == \"high\" or x == \"low\" or x == \"高\" or x == \"低\" else np.nan\n",
    "y_real = r_real.applymap(judge1)\n",
    "y_pre = r_pre.applymap(judge1)\n",
    "# 转换为数字\n",
    "def tran1(x):\n",
    "    if x == \"high\" or x == \"高\":\n",
    "        return 1\n",
    "    elif x == \"low\" or x == \"低\":\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "y_real = y_real.applymap(tran1)\n",
    "y_pre = y_pre.applymap(tran1)\n",
    "# 恢复索引\n",
    "y_real[\"Speaker\"] = r_real[\"Speaker\"]\n",
    "y_pre[\"Speaker\"] = r_pre[\"Speaker\"]\n",
    "# 求平均值，以达到去重复\n",
    "def tran2(x):\n",
    "    if np.isnan(x) or x == 0.5:\n",
    "        return np.nan\n",
    "    elif x > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "y_pre = y_pre.groupby(by=[\"Speaker\"]).mean().applymap(tran2)\n",
    "y_real = y_real.groupby(by=[\"Speaker\"]).mean()\n",
    "# 让真实值和预测值之间的长度统一\n",
    "y_real = y_real.loc[[np.any(y_pre.index == i) for i in y_real.index],:]\n",
    "\n",
    "for v in [\"Neuroticism\", \"Extraversion\", \"Openness\", \"Agreeableness\", \"Conscientiousness\"]:\n",
    "    print(v, end=\"\\t\")\n",
    "    print(1 - np.sum(\n",
    "        [abs(y_real[v][i] - (y_pre[v][i] if not np.isnan(y_pre[v][i]) else y_real[v][i] - 1)) for i in y_pre.index]) / y_pre.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c83757f6c30423986c3fbe55670954346c835ad41fee96d431030808e97aca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
